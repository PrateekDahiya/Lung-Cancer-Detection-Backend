{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import cv2\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lung_aca', 'lung_n', 'lung_scc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'lung_colon_image_set/lung_image_sets'\n",
    "classes = os.listdir(path)\n",
    "classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'lung_colon_image_set/lung_image_sets'\n",
    "\n",
    "for cat in classes:\n",
    "\timage_dir = f'{path}/{cat}'\n",
    "\timages = os.listdir(image_dir)\n",
    "\n",
    "\tfig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\tfig.suptitle(f'Images for {cat} category . . . .', fontsize=20)\n",
    "\n",
    "\tfor i in range(3):\n",
    "\t\tk = np.random.randint(0, len(images))\n",
    "\t\timg = np.array(Image.open(f'{path}/{cat}/{images[k]}'))\n",
    "\t\tax[i].imshow(img)\n",
    "\t\tax[i].axis('off')\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE =128\n",
    "SPLIT = 0.2\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i, cat in enumerate(classes):\n",
    "\timages = glob(f'{path}/{cat}/*.jpeg')\n",
    "\n",
    "\tfor image in images:\n",
    "\t\timg = cv2.imread(image)\n",
    "\t\t\n",
    "\t\tX.append(cv2.resize(img, (IMG_SIZE, IMG_SIZE)))\n",
    "\t\tY.append(i)\n",
    "\n",
    "X = np.asarray(X)\n",
    "one_hot_encoded_Y = pd.get_dummies(Y).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 128, 128, 3) (3000, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, one_hot_encoded_Y, test_size = SPLIT,random_state = 2022)\n",
    "print(X_train.shape, X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Shashank kumar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "\tlayers.Conv2D(filters=32,\n",
    "\t\t\t\tkernel_size=(5, 5),\n",
    "\t\t\t\tactivation='relu',\n",
    "\t\t\t\tinput_shape=(IMG_SIZE,\n",
    "\t\t\t\t\t\t\tIMG_SIZE,\n",
    "\t\t\t\t\t\t\t3),\n",
    "\t\t\t\tpadding='same'),\n",
    "\tlayers.MaxPooling2D(2, 2),\n",
    "\n",
    "\tlayers.Conv2D(filters=64,\n",
    "\t\t\t\tkernel_size=(3, 3),\n",
    "\t\t\t\tactivation='relu',\n",
    "\t\t\t\tpadding='same'),\n",
    "\tlayers.MaxPooling2D(2, 2),\n",
    "\n",
    "\tlayers.Conv2D(filters=128,\n",
    "\t\t\t\tkernel_size=(3, 3),\n",
    "\t\t\t\tactivation='relu',\n",
    "\t\t\t\tpadding='same'),\n",
    "\tlayers.MaxPooling2D(2, 2),\n",
    "\n",
    "\tlayers.Flatten(),\n",
    "\tlayers.Dense(256, activation='relu'),\n",
    "\tlayers.BatchNormalization(),\n",
    "\tlayers.Dense(128, activation='relu'),\n",
    "\tlayers.Dropout(0.3),\n",
    "\tlayers.BatchNormalization(),\n",
    "\tlayers.Dense(3, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(\n",
    "\tmodel,\n",
    "\tshow_shapes = True,\n",
    "\tshow_dtype = True,\n",
    "\tshow_layer_activations = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "\toptimizer = 'adam',\n",
    "\tloss = 'categorical_crossentropy',\n",
    "\tmetrics = ['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "\tdef on_epoch_end(self, epoch, logs={}):\n",
    "\t\tif logs.get('val_accuracy') > 0.90:\n",
    "\t\t\tprint('\\n Validation accuracy has reached upto \\\n",
    "\t\t\t\t\t90% so, stopping further training.')\n",
    "\t\t\tself.model.stop_training = True\n",
    "\n",
    "\n",
    "es = EarlyStopping(patience=3,\n",
    "\t\t\t\tmonitor='val_accuracy',\n",
    "\t\t\t\trestore_best_weights=True)\n",
    "\n",
    "lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "\t\t\t\t\tpatience=2,\n",
    "\t\t\t\t\tfactor=0.5,\n",
    "\t\t\t\t\tverbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "\t\t\t\t\tvalidation_data = (X_val, Y_val),\n",
    "\t\t\t\t\tbatch_size = BATCH_SIZE,\n",
    "\t\t\t\t\tepochs = EPOCHS,\n",
    "\t\t\t\t\tverbose = 1,\n",
    "\t\t\t\t\tcallbacks = [es, lr, myCallback()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:,['loss','val_loss']].plot()\n",
    "history_df.loc[:,['accuracy','val_accuracy']].plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_val)\n",
    "Y_val = np.argmax(Y_val, axis=1)\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(Y_val, Y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(Y_val, Y_pred,\n",
    "\t\t\t\t\t\t\t\t\ttarget_names=classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lung_cancer_model.h5\")\n",
    "model.save(\"lung_cancer_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:48: SyntaxWarning: invalid escape sequence '\\l'\n",
      "<>:48: SyntaxWarning: invalid escape sequence '\\l'\n",
      "C:\\Users\\Shashank kumar\\AppData\\Local\\Temp\\ipykernel_19388\\1130306805.py:48: SyntaxWarning: invalid escape sequence '\\l'\n",
      "  'lung_colon_image_set\\lung_image_sets\\lung_scc\\lungscc1.jpeg',\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\n",
      "[lungscc1.jpeg]\n",
      "  Softmax scores: [0. 0. 1.]\n",
      "  → Predicted: 2 lung_scc\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "[lungn1.jpeg]\n",
      "  Softmax scores: [0.0027 0.9973 0.    ]\n",
      "  → Predicted: 1 lung_n\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "[Random noise]\n",
      "  Softmax scores: [0. 1. 0.]\n",
      "  → Class index: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# ─── 1) Load your model ───────────────────────────────────────────────────────\n",
    "# No need to compile since we're only doing inference\n",
    "model = tf.keras.models.load_model('lung_cancer_model.h5', compile=False)\n",
    "\n",
    "# ─── 2) Helper: preprocess to match training (BGR [0–255], no scaling) ─────\n",
    "def preprocess_image_bgr_noscale(path, img_size=128):\n",
    "    \"\"\"\n",
    "    Reads an image as BGR uint8 [0–255], resizes to (img_size, img_size),\n",
    "    and adds a batch dimension—NO RGB conversion, NO float32 scaling.\n",
    "    Returns a numpy array of shape (1, img_size, img_size, 3).\n",
    "    \"\"\"\n",
    "    img = cv2.imread(path)  # BGR, uint8 [0–255]\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Could not read image at {path!r}\")\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    # keep dtype uint8; the model was trained on these raw values\n",
    "    return np.expand_dims(img, axis=0)\n",
    "\n",
    "# ─── 3) Inference function ──────────────────────────────────────────────────\n",
    "def predict_image(path, img_size=128, class_names=None):\n",
    "    \"\"\"\n",
    "    Preprocesses + predicts a single image.\n",
    "    Prints softmax scores and class index (and name if provided).\n",
    "    \"\"\"\n",
    "    x = preprocess_image_bgr_noscale(path, img_size=img_size)\n",
    "    preds = model.predict(x)\n",
    "    cls_idx = np.argmax(preds, axis=1)[0]\n",
    "    scores = preds.flatten()\n",
    "    print(f\"\\n[{os.path.basename(path)}]\")\n",
    "    print(\"  Softmax scores:\", np.round(scores, 4))\n",
    "    if class_names:\n",
    "        print(\"  → Predicted:\", cls_idx, class_names[cls_idx])\n",
    "    else:\n",
    "        print(\"  → Predicted class index:\", cls_idx)\n",
    "    return cls_idx, scores\n",
    "\n",
    "# ─── 4) Define your class-label mapping ──────────────────────────────────────\n",
    "# (must match `classes = os.listdir(path)` ordering from training)\n",
    "class_names = ['lung_aca', 'lung_n', 'lung_scc']  # example order\n",
    "\n",
    "# ─── 5) Test on one or more images ───────────────────────────────────────────\n",
    "test_paths = [\n",
    "    'lung_colon_image_set\\lung_image_sets\\lung_scc\\lungscc1.jpeg',\n",
    "    'lung_colon_image_set/lung_image_sets/lung_n/lungn1.jpeg',\n",
    "    # add more paths here...\n",
    "]\n",
    "\n",
    "for tp in test_paths:\n",
    "    predict_image(tp, img_size=128, class_names=class_names)\n",
    "\n",
    "# ─── 6) (Optional) Sanity-check on random noise ─────────────────────────────\n",
    "noise = (np.random.randint(0, 256, size=(1,128,128,3), dtype=np.uint8))\n",
    "preds_noise = model.predict(noise)\n",
    "print(\"\\n[Random noise]\")\n",
    "print(\"  Softmax scores:\", np.round(preds_noise.flatten(),4))\n",
    "print(\"  → Class index:\", np.argmax(preds_noise, axis=1)[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
